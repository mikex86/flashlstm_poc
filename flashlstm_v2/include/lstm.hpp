#pragma once

#include <cstddef>
#include <cuda_fp16.h>
#include <cuda_runtime_api.h>

namespace flstm {

enum class GateCacheDType : int {
    kFloat32 = 0,
    kFloat16 = 1,
};

struct GateCacheHost {
    void *h_ptr;
    void *c_ptr;
};

struct StreamingLstmOptions {
    GateCacheDType h_dtype = GateCacheDType::kFloat32;
    GateCacheDType c_dtype = GateCacheDType::kFloat32;
};

/**
 * Forward pass for a single-layer LSTM operating entirely on CUDA buffers.
 *
 * Inputs:
 *   - x_tensor_host:     (T, B, I) in pinned host memory (__half)
 *   - h0_device / c0_device: initial states on device (__half, shape B x H)
 *   - weights_ih / weights_hh: FP32 weights on device (4H x I / 4H x H)
 *   - bias_ih / bias_hh: FP32 biases on device (4H)
 *
 * Outputs:
 *   - y_tensor_host:     (T, B, H) in pinned host memory (__half)
 *   - gate_cache_host:   pair of pinned buffers storing (⌈T / R⌉, B, H) h and c
 *                        checkpoints captured every `recompute_interval`
 *                        steps. Each buffer's dtype is selected via
 *                        StreamingLstmOptions allowing mixed-precision caches.
 *   - compute_stream / h2d_stream / d2h_stream: distinct CUDA streams used for
 *         GEMMs, host→device transfers, and device→host transfers respectively.
 *         All three stream handles must be different to enable overlap.
 */
void StreamingLstmForward(
    size_t time_steps,
    size_t batch_size,
    size_t input_size,
    size_t hidden_size,
    size_t recompute_interval,

    const __half *x_tensor_host,
    const __half *h0_device,
    const __half *c0_device,

    const float *weights_ih,
    const float *weights_hh,
    const float *bias_ih,
    const float *bias_hh,

    __half *y_tensor_host,

    GateCacheHost gate_cache_host,
    StreamingLstmOptions options,
    __half *hy_device,
    __half *cy_device,

    cudaStream_t compute_stream,
    cudaStream_t h2d_stream,
    cudaStream_t d2h_stream
);

/**
 * Backward pass consuming caches generated by StreamingLstmForward.
 *
 * Inputs:
 *   - x_tensor_host:    (T, B, I) inputs in pinned host memory (__half)
 *   - gate_cache_host:  pinned buffers containing the h and c checkpoints
 *                       captured during the forward pass using the dtype
 *                       configured in StreamingLstmOptions.
 *   - dY_tensor_host:   upstream grads w.r.t outputs in host half precision
 *   - d_hn_device / d_cn_device: grads for final states (nullable)
 *   - c0_device:        initial cell state provided in half precision (B, H)
 *   - weights_ih / weights_hh: forward weights (FP32) reused for GEMMs
 *   - bias_ih / bias_hh: fused bias terms reused during recomputation
 *
 * Outputs:
 *   - dx_tensor_host:   gradients w.r.t. inputs written in host half precision
 *   - dW_ih / dW_hh / db_ih / db_hh: parameter gradients (FP32, device)
 *   - dh0_out / dc0_out: gradients for initial states (FP32, device)
 *   - compute_stream / h2d_stream / d2h_stream: distinct CUDA streams used for
 *         GEMMs and kernels, host→device transfers, and device→host transfers
 *         respectively. All three stream handles must be different to enable
 *         full-overlap streaming behaviour.
 */
void StreamingLstmBackward(
    size_t time_steps,
    size_t batch_size,
    size_t input_size,
    size_t hidden_size,
    size_t recompute_interval,

    const __half *x_tensor_host,
    const __half *y_tensor_host,
    GateCacheHost gate_cache_host,
    StreamingLstmOptions options,

    const __half *dY_tensor_host,
    const __half *d_hn_device,
    const __half *d_cn_device,
    const __half *h0_device,
    const __half *c0_device,

    const float *weights_ih,
    const float *weights_hh,
    const float *bias_ih,
    const float *bias_hh,

    __half *dx_tensor_host,
    float *dW_ih,
    float *dW_hh,
    float *db_ih,
    float *db_hh,
    float *dh0_out,
    float *dc0_out,

    cudaStream_t compute_stream,
    cudaStream_t h2d_stream,
    cudaStream_t d2h_stream
);

} // namespace flstm

extern "C" {

typedef enum {
    FLSTM_GATE_CACHE_FLOAT32 = 0,
    FLSTM_GATE_CACHE_FLOAT16 = 1,
} flstm_GateCacheDType;

typedef struct {
    void *h_ptr;
    void *c_ptr;
} flstm_GateCacheHost;

typedef struct {
    flstm_GateCacheDType h_dtype;
    flstm_GateCacheDType c_dtype;
} flstm_StreamingLstmOptions;

void flstm_StreamingLstmForward(
    size_t time_steps,
    size_t batch_size,
    size_t input_size,
    size_t hidden_size,
    size_t recompute_interval,

    const __half *x_tensor_host,
    const __half *h0_device,
    const __half *c0_device,

    const float *weights_ih,
    const float *weights_hh,
    const float *bias_ih,
    const float *bias_hh,

    __half *y_tensor_host,

    flstm_GateCacheHost gate_cache_host,
    const flstm_StreamingLstmOptions *options,
    __half *hy_device,
    __half *cy_device,

    cudaStream_t compute_stream,
    cudaStream_t h2d_stream,
    cudaStream_t d2h_stream
);

void flstm_StreamingLstmBackward(
    size_t time_steps,
    size_t batch_size,
    size_t input_size,
    size_t hidden_size,
    size_t recompute_interval,

    const __half *x_tensor_host,
    const __half *y_tensor_host,
    flstm_GateCacheHost gate_cache_host,

    const __half *dY_tensor_host,
    const __half *d_hn_device,
    const __half *d_cn_device,
    const __half *h0_device,
    const __half *c0_device,

    const float *weights_ih,
    const float *weights_hh,
    const float *bias_ih,
    const float *bias_hh,

    __half *dx_tensor_host,
    float *dW_ih,
    float *dW_hh,
    float *db_ih,
    float *db_hh,
    float *dh0_out,
    float *dc0_out,

    cudaStream_t compute_stream,
    cudaStream_t h2d_stream,
    cudaStream_t d2h_stream,
    const flstm_StreamingLstmOptions *options
);

} // extern "C"
